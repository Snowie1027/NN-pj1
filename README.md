# NN-pj1
# Project-1: Neural Network and Deep Learning

## 基本信息

- **学号**：22307130420  
- **专业**：数据科学与大数据技术  
- **日期**：2025年4月6日  

---

## 📖 项目简介

本项目为“Neural Network and Deep Learning”课程的第一次大作业，旨在**从零实现一个神经网络框架**，并应用于 MNIST 手写数字识别任务。区别于直接调用深度学习框架（如 PyTorch 或 TensorFlow），本项目手动实现了包括线性层、卷积层、优化器、损失函数等在内的所有核心模块，力求深入理解神经网络的本质。

---

## 📚 目录结构

- [1. 引言](#1-引言)  
- [2. 方法](#2-方法)  
- [3. 实验与结果](#3-实验与结果)  
- [4. 讨论](#4-讨论)  
- [5. 结论](#5-结论)  
- [6. 参考文献](#6-参考文献)  
- [7. 附录](#7-附录)  

---

## 1. 引言

### 1.1 研究背景与问题定义

随着人工智能的发展，神经网络在图像识别领域发挥着越来越重要的作用。MNIST 数据集因其简洁性与代表性，被广泛用于图像分类模型的验证与教学实验。本项目从零实现神经网络模型，深入剖析神经网络各个组件的原理与运作机制。

### 1.2 目标与目的

- 构建完整的神经网络训练与推理流程  
- 实现 MLP 与 CNN 两类模型  
- 探索优化器、正则化、学习率调度等训练策略  
- 实现模型性能可视化与分析  

---

## 2. 方法

### 2.1 数据集概述

使用 MNIST 手写数字数据集，共 70,000 张 28×28 灰度图像，其中训练集 60,000 张，测试集 10,000 张。

### 2.2 神经网络模型

#### 多层感知机（MLP）
- 输入层：784 维（28×28）
- 隐藏层：128 或两层结构 [256, 128]，使用 ReLU
- 输出层：10 类别，Softmax 激活

#### 卷积神经网络（CNN）
- 卷积层：8/16 个 3×3 卷积核，提取局部特征
- 池化层：2×2 最大池化
- Flatten 层：特征展开
- 全连接层+Softmax输出

### 2.3 修改与改进

#### 2.3.1 网络结构调整
- 加深 MLP 层数与宽度  
- 增加 CNN 层数与通道数  

#### 2.3.2 训练过程的改进
- 支持多优化器：SGD、Momentum、MomentGD  
- 引入学习率调度策略  

#### 2.3.3 正则化方法
- 实现 L2 正则化  
- 计划加入 Dropout 和 Early Stopping  

#### 2.3.4 交叉熵损失与 Softmax
- 实现 `MultiCrossEntropyLoss`  
- 输出层使用 Softmax 函数  

#### 2.3.5 数据增强
- 包括平移、旋转、缩放等操作  

---

## 3. 实验与结果

### 3.1 性能评估指标
- 准确率（Accuracy）  
- 损失变化曲线  

### 3.2 实验结果

#### 3.2.1 不同结构性能对比
- MLP 与 CNN 在准确率与泛化能力方面对比明显

#### 3.2.2 超参数影响分析
- 学习率、批次大小、隐藏层结构等对性能影响显著

#### 3.2.3 数据增强效果
- 提升泛化能力，避免过拟合

### 3.3 可视化
- 权重热图、训练曲线等辅助分析工具

---

## 4. 讨论

### 4.1 结果分析
- CNN 在图像任务中表现优于 MLP  
- 合理结构调整与调参提升模型表现

### 4.2 模型优缺点
- 手动实现代码灵活性高，但训练效率低于成熟框架

### 4.3 改进方向
- 引入 BatchNorm、Dropout  
- 多线程训练与 GPU 加速  

---

## 5. 结论

### 5.1 总结实验发现
- 手动实现帮助加深理解  
- 不同结构与调参方法对性能有显著影响  

### 5.2 未来工作方向
- 更复杂数据集迁移（如 CIFAR-10）  
- 模块结构进一步优化与封装  

---

## 6. 参考文献

1. LeCun, Y., et al. (1998). Gradient-based learning applied to document recognition. *Proceedings of the IEEE*.  
2. Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.  
3. MNIST 数据集官网: http://yann.lecun.com/exdb/mnist/  

---

## 7. 附录

### 7.1 代码链接

> [GitHub 仓库地址](https://github.com/Snowie1027/NN-pj1)

### 7.2 数据与模型权重下载

> 数据集已集成于 `dataset/MNIST` 文件夹  
> 模型权重文件存储于 `saved_models/` 与 `best_models/` 中

>[数据集与模型权重](https://drive.google.com/drive/folders/1CuHjaBsuGuZEXRcQvxnmWBgK4zZBdf0-?usp=sharing)
---

感谢阅读！
